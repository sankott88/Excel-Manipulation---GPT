{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db618460-3c14-43ad-89d5-37b8ca3c4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client with your API key\n",
    "import openai\n",
    "openai.api_key = \"key_here\"  # Replace with your actual API key\n",
    "client = openai.OpenAI(api_key=\"key_here\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3830b875",
   "metadata": {},
   "source": [
    "Cookie Sheet processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb7723-84e1-4131-8f6d-732b75dd4c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extraction done\n",
      "                 Domain               Name                     Value  \\\n",
      "0  cffs.edsced-sltc.com  ASP.NET_SessionId  y1xq3ccirdolwquu2xmqnb3z   \n",
      "\n",
      "  Expiration Lifespan  ThirdParty  Path Secure  HTTP Only  Source  \\\n",
      "0    Session  Session       False   NaN    Yes      False  script   \n",
      "\n",
      "                         Set By                          Page Category  \\\n",
      "0  https://cffs.edsced-sltc.com  https://cffs.edsced-sltc.com            \n",
      "\n",
      "  Description  \n",
      "0              \n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Used to maintain an anonymized user session by the server.\"\n",
      "}\n",
      "Got the category done!\n",
      "all dates:Series([], Name: Expiration, dtype: datetime64[ns])\n",
      "Minimum date is:NaT\n",
      "min_date is NaT. Cannot format, so using current date 2025-07-17T12:04:43.000Z\n",
      "Done,Done-APM0006263 - CFFS-Manual-Cookie-Scan-Report.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Load template and input Excel files\n",
    "#template = pd.ExcelFile('template.xlsx')\n",
    "input_file_name = \"APM0006263 - CFFS-Manual-Cookie-Scan-Report.xlsx\"\n",
    "output_file_name = \"Done-APM0006263 - CFFS-Manual-Cookie-Scan-Report.xlsx\"\n",
    "input_data = pd.read_excel(input_file_name, sheet_name=None)  # read all sheets into a dict of DataFrames\n",
    "print(\"File extraction done\")\n",
    "\n",
    "# Process Cookies sheet\n",
    "try:\n",
    "    cookies_df = input_data.get('Cookies')\n",
    "    #Ensure required columns exist\n",
    "    for col in ['Category', 'Description']:\n",
    "          if col not in cookies_df.columns:\n",
    "                 cookies_df[col] = '' #Add new column if not exist\n",
    "    print(cookies_df.head())\n",
    "except:\n",
    "    print(\"The document does not have cookie sheet\")\n",
    "\n",
    "import time\n",
    "#If needed include the key here\n",
    "openai.api_key = \"key_here\"  # Replace with your actual API key\n",
    "client = openai.OpenAI(api_key=\"key_here\")\n",
    "\n",
    "cookies_df['Description'] = cookies_df['Description'].astype(str)\n",
    "cookies_df['Category'] = cookies_df['Category'].astype(str)\n",
    "\n",
    "# Iterate through each row in Cookies sheet\n",
    "for i, row in cookies_df.iterrows():\n",
    "    name = row['Name']  # get the cookie name\n",
    "    expiration = row['Expiration']  # get expiration value\n",
    "    lifespan = row['Lifespan']  # get lifespan value\n",
    "    # Check and format expiration date or lifespan\n",
    "    if expiration == 'Infinity':\n",
    "            # If expiration is Infinity, set lifespan as Session\n",
    "            cookies_df.at[i, 'Lifespan'] = 'Session'    \n",
    "    elif lifespan == 'Session':\n",
    "        # If lifespan is Session, set the expiration as Infinity\n",
    "        cookies_df.at[i, 'Expiration'] = 'Infinity'\n",
    "    elif pd.notnull(expiration) and expiration != 'Infinity': \n",
    "        # Format valid date to required ISO format\n",
    "        expiration = str(expiration).strip()  # remove spaces\n",
    "        expiration = expiration.replace('/', '-')  # replace slashes with dashes if needed\n",
    "        expiration = pd.to_datetime(expiration,errors='coerce').strftime('%Y-%m-%dT%H:%M:%S.000Z')    \n",
    "        print(\"log:\",expiration)\n",
    "        cookies_df.at[i, 'Expiration'] = expiration\n",
    "        cookies_df.at[i, 'Lifespan'] = 'Permanent'\n",
    "# Call ChatGPT to categorize cookie and generate description\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a cookie categorizer.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Return JSON object with keys 'Category' and 'Description' for cookie name {name} choose the category from: 'Strictly Necessary Cookies', 'Advertising and Targetting Cookie's, 'Functional Cookies', 'Analytics and Performance Cookies' and description value must be short one line for the web cookie named {name}\"}],\n",
    "        temperature=0 )\n",
    "    text = response.choices[0].message.content.strip()  # remove any extra spaces/newlines\n",
    "    print(\"GPT:\",text)\n",
    "    result = json.loads(text)  # parse JSON\n",
    "    cookies_df.at[i, 'Category'] = result.get('Category', '').strip()\n",
    "    cookies_df.at[i, 'Description'] = result.get('Description', '').strip()\n",
    "    sucess = True #done!\n",
    "    print(f\"Got the category done!\")\n",
    "\n",
    "import openpyxl\n",
    "# Find lowest expiration timestamp\n",
    "\n",
    "# Extract the expiration dates after 2000 year\n",
    "cookies_df['Expiration'] = pd.to_datetime(cookies_df['Expiration'],errors = 'coerce')\n",
    "valid_dates = cookies_df[cookies_df['Expiration'].dt.year>=2000]['Expiration']\n",
    "print(f\"all dates:{valid_dates}\")\n",
    "\n",
    "# Find the lowest year to find the cookie scan date\n",
    "min_date = valid_dates.min()\n",
    "print(f\"Minimum date is:{min_date}\")\n",
    "\n",
    "# convert the lowest date into iSO standards\n",
    "if pd.notna(min_date):\n",
    "     manual_scan_date = min_date.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "     print(f\"manual_scan_date is:{manual_scan_date}\")\n",
    "else:\n",
    "     manual_scan_date = datetime.now().strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "     print(f\"min_date is NaT. Cannot format, so using current date {manual_scan_date}\")\n",
    "    \n",
    "# Format the expiration date format, only for the dates.\n",
    "cookies_df['Expiration'] = cookies_df['Expiration'].where(\n",
    "    cookies_df['Expiration'].apply(lambda x: isinstance(x,pd.Timestamp)), pd.NaT\n",
    ").apply(lambda x: x.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\") if pd.notna(x) else 'Infinity')\n",
    "\n",
    "# print(\"DataFrame shape:\",cookies_df.shape)\n",
    "# print(\"Column names:\",cookies_df.columns.tolist())\n",
    "# print(\"Last 5 rows:\\n\",cookies_df.head())\n",
    "\n",
    "#Avoid duplicating footer rows and Append Timestamp and Website info\n",
    "if not cookies_df.iloc[-3:, 0].str.contains(\"Time stamp of Manual Scan run\").any():     \n",
    "    cookies_df.loc[len(cookies_df)] = [''] * len(cookies_df.columns)     \n",
    "    cookies_df.loc[len(cookies_df)] = ['Time stamp of Manual Scan run', manual_scan_date] + [''] * (len(cookies_df.columns) - 2)     \n",
    "    domain_value = cookies_df['Domain'].iloc[0] if 'Domain' in cookies_df.columns else ''     \n",
    "    cookies_df.loc[len(cookies_df)] = ['Website', domain_value] + [''] * (len(cookies_df.columns) - 2) \n",
    "\n",
    "# Convert all to string before writing to Excel \n",
    "cookies_df = cookies_df.astype(str)\n",
    "\n",
    "# Write updated data to new Excel files\n",
    "with pd.ExcelWriter(output_file_name,engine='openpyxl') as writer:\n",
    "    cookies_df.to_excel(writer, sheet_name='Cookies', index=False)\n",
    "\n",
    "print(f\"Done,{output_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0c121",
   "metadata": {},
   "source": [
    "Local Sheet processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8caddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Domain  \\\n",
      "0  dcffinracompliance.deloitte.com   \n",
      "1  dcffinracompliance.deloitte.com   \n",
      "2  dcffinracompliance.deloitte.com   \n",
      "3  dcffinracompliance.deloitte.com   \n",
      "4  dcffinracompliance.deloitte.com   \n",
      "\n",
      "                                                 Key  \\\n",
      "0  msal.556f8b97-2187-4ed5-beda-6f24aa153330.acti...   \n",
      "1  fc0dd5e1-b923-4f25-b4e2-a1ed761c7e07.36da45f1-...   \n",
      "2  fc0dd5e1-b923-4f25-b4e2-a1ed761c7e07.36da45f1-...   \n",
      "3                                        UserEmailID   \n",
      "4                                       isAuthorized   \n",
      "\n",
      "                     Category  Description  \n",
      "0  Strictly necessary cookies          NaN  \n",
      "1  Strictly necessary cookies          NaN  \n",
      "2  Strictly necessary cookies          NaN  \n",
      "3  Strictly necessary cookies          NaN  \n",
      "4  Strictly necessary cookies          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Process Local sheet\n",
    "try:\n",
    "    local_df = input_data.get('Local Storage')\n",
    "    \n",
    "    for col in ['Category', 'Description']:\n",
    "        if col not in local_df.columns:\n",
    "            local_df[col] = '' #Add new column if not exist\n",
    "    \n",
    "    print(local_df.head())\n",
    "except:\n",
    "    print(\"There is no Local Storage sheet exist\")\n",
    "#Ensure required columns exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2baefe9d-9c59-497f-842f-4fa7ac1f1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT: {\n",
      "  \"Category\": \"Strictly Necessary Cookies\",\n",
      "  \"Description\": \"Essential for user authentication and account management.\"\n",
      "}\n",
      "Got the category done for local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\skotteeswaran\\AppData\\Local\\Temp\\ipykernel_5160\\1917192650.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Essential for user authentication and account management.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  local_df.at[i, 'Description'] = result.get('Description', '').strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Essential for user authentication and access to user profile and directory information.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Essential for user authentication and security purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Stores the user's email ID for essential website functionality.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Essential for user authentication and security purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "  \"Category\": \"Functional Cookies\",\n",
      "  \"Description\": \"Stores active account filters for user convenience.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "  \"Category\": \"Strictly Necessary Cookies\",\n",
      "  \"Description\": \"Essential for user authentication and security purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "  \"Category\": \"Strictly Necessary Cookies\",\n",
      "  \"Description\": \"Essential for user authentication and security purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Essential for user authentication and security purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Essential for website functionality, stores user's chosen username.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Strictly Necessary Cookies\",\n",
      "    \"Description\": \"Essential for user authentication on login.windows.net\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Analytics and Performance Cookies\",\n",
      "    \"Description\": \"Cookie used for tracking and analyzing user behavior for performance optimization.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "    \"Category\": \"Analytics and Performance Cookies\",\n",
      "    \"Description\": \"Cookie used for tracking application names in Adobe Reactor for analytics purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n",
      "GPT: {\n",
      "  \"Category\": \"Analytics and Performance Cookies\",\n",
      "  \"Description\": \"Used to track visitor ID for analytics purposes.\"\n",
      "}\n",
      "Got the category done for local storage\n"
     ]
    }
   ],
   "source": [
    "# Process Local Storage sheet\n",
    "local_df = input_data.get('Local Storage')\n",
    "if local_df is not None:\n",
    "    for i, row in local_df.iterrows():\n",
    "        key = row['Key']  # key name\n",
    " \n",
    "        # Call ChatGPT to get category and description\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a cookie categorizer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Return JSON object with keys 'Category' and 'Description' for local storage cookie name {key} choose the category from: 'Strictly Necessary Cookies', 'Advertising and Targetting Cookie's, 'Functional Cookies', 'Analytics and Performance Cookies' and description value must be short one line for the web cookie named {key}\"}],\n",
    "            temperature=0 )\n",
    "        text = response.choices[0].message.content.strip()  # remove any extra spaces/newlines\n",
    "        print(\"GPT:\",text)\n",
    "        result = json.loads(text)  # parse JSON\n",
    "        local_df.at[i, 'Category'] = result.get('Category', '').strip()\n",
    "        local_df.at[i, 'Description'] = result.get('Description', '').strip()\n",
    "        sucess = True #done!\n",
    "        print(f\"Got the category done for local storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1617a8-162a-49c9-98bd-0c9f6a5bb71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Write updated data to new Excel files\n",
    "with pd.ExcelWriter(output_file_name,engine='openpyxl', mode='a', if_sheet_exists ='replace') as writer:\n",
    "    local_df.to_excel(writer, sheet_name='Local Storage', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633683cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Cookies sheet\n",
    "try:\n",
    "    session_df = input_data.get('Session Storage')\n",
    "    \n",
    "    for col in ['Category', 'Description']:\n",
    "        if col not in session_df.columns:\n",
    "            session_df[col] = '' #Add new column if not exist\n",
    "    \n",
    "    print(session_df.head())\n",
    "except:\n",
    "    print(\"There is no Session Storage sheet exist\")\n",
    "#Ensure required columns exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014f811-4885-4579-9466-39c6f7cf9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Session Storage sheet\n",
    "session_df = input_data.get('Session Storage')\n",
    "if session_df is not None:\n",
    "    for i, row in session_df.iterrows():\n",
    "        key = row['Key']  # key name\n",
    " \n",
    "        # Call ChatGPT to get category and description\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a cookie categorizer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Return JSON object with keys 'Category' and 'Description' for session storage cookie name {key} choose the category from: 'Strictly Necessary Cookies', 'Advertising and Targetting Cookie's, 'Functional Cookies', 'Analytics and Performance Cookies' and description value must be short one line for the web cookie named {key}\"}],\n",
    "            temperature=0 )\n",
    "        text = response.choices[0].message.content.strip()  # remove any extra spaces/newlines\n",
    "        print(\"GPT:\",text)\n",
    "        result = json.loads(text)  # parse JSON\n",
    "        session_df.at[i, 'Category'] = result.get('Category', '').strip()\n",
    "        session_df.at[i, 'Description'] = result.get('Description', '').strip()\n",
    "        sucess = True #done!\n",
    "        print(f\"Got the category done for Session storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac834c4-9ea1-4173-9a3e-4c0133b332e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write updated data to new Excel files\n",
    "with pd.ExcelWriter(output_file_name,engine='openpyxl', mode='a', if_sheet_exists ='replace') as writer:\n",
    "    session_df.to_excel(writer, sheet_name='Session Storage', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0faff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
