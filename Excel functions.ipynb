{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db618460-3c14-43ad-89d5-37b8ca3c4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv #load the key from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from .env file if exists\n",
    "load_dotenv()\n",
    "\n",
    "#Read from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3830b875",
   "metadata": {},
   "source": [
    "Cookie Sheet processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb7723-84e1-4131-8f6d-732b75dd4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Load template and input Excel files\n",
    "#template = pd.ExcelFile('template.xlsx')\n",
    "input_file_name = \"APM0004066 - Deloitte Assistant - Cookies_Assistant.xlsx\"\n",
    "output_file_name = \"Done-APM0004066 - Deloitte Assistant - Cookies_Assistant.xlsx\"\n",
    "input_data = pd.read_excel(input_file_name, sheet_name=None)  # read all sheets into a dict of DataFrames\n",
    "print(\"File extraction done\")\n",
    "\n",
    "# Process Cookies sheet\n",
    "try:\n",
    "    cookies_df = input_data.get('Cookies')\n",
    "    #Ensure required columns exist\n",
    "    for col in ['Category', 'Description']:\n",
    "          if col not in cookies_df.columns:\n",
    "                 cookies_df[col] = '' #Add new column if not exist\n",
    "    print(cookies_df.head())\n",
    "except:\n",
    "    print(\"The document does not have cookie sheet\")\n",
    "\n",
    "cookies_df['Description'] = cookies_df['Description'].astype(str)\n",
    "cookies_df['Category'] = cookies_df['Category'].astype(str)\n",
    "\n",
    "# Iterate through each row in Cookies sheet\n",
    "for i, row in cookies_df.iterrows():\n",
    "    name = row['Name']  # get the cookie name\n",
    "    expiration = row['Expiration']  # get expiration value\n",
    "    lifespan = row['Lifespan']  # get lifespan value\n",
    "    thirdparty = row['ThirdParty'] # get Thirdparty value\n",
    "    setby = row['Set By'] # get the setby value\n",
    "    domain = row['Domain'] # get the domain name\n",
    "    cookies_df.columns = cookies_df.columns.str.strip()\n",
    "\n",
    "    if thirdparty == \"\" or (domain == cookies_df['Domain'].iloc[0] or domain.endswith(\".\"+cookies_df['Domain'].iloc[0])):\n",
    "         cookies_df.at[i, 'ThirdParty'] = 'FALSE'\n",
    "    else:\n",
    "         cookies_df.at[i, 'ThirdParty'] = 'TRUE'\n",
    "    \n",
    "    #if row['Set By'] =='nan':\n",
    "    if pd.isna(row['Set By']):\n",
    "         cookies_df.at[i, 'Set By'] = \"https://\"+domain\n",
    "\n",
    "    # Check and format expiration date or lifespan\n",
    "    if pd.isnull(expiration) or str(expiration).strip().lower()=='session':\n",
    "        cookies_df.at[i, 'Expiration'] = 'Infinity'\n",
    "        cookies_df.at[i, 'Lifespan'] = 'Session'\n",
    "    elif expiration == 'Infinity':\n",
    "        # If expiration is Infinity, set lifespan as Session\n",
    "        cookies_df.at[i, 'Lifespan'] = 'Session'  \n",
    "    elif lifespan == 'Session':\n",
    "        # If lifespan is Session, set the expiration as Infinity\n",
    "        cookies_df.at[i, 'Expiration'] = 'Infinity'\n",
    "    elif pd.notnull(expiration) and expiration != 'Infinity': \n",
    "        # Format valid date to required ISO format\n",
    "        expiration = str(expiration).strip()  # remove spaces\n",
    "        expiration = expiration.replace('/', '-')  # replace slashes with dashes if needed\n",
    "        expiration = pd.to_datetime(expiration,errors='coerce').strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "        print(\"log:\",expiration)\n",
    "        cookies_df.at[i, 'Expiration'] = expiration\n",
    "        cookies_df.at[i, 'Lifespan'] = 'Permanent'\n",
    "\n",
    "# Call ChatGPT to categorize cookie and generate description\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a cookie categorizer.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Return JSON object with keys 'Category' and 'Description' for cookie name {name} choose the category from: 'Strictly Necessary Cookies', 'Advertising and Targetting Cookie's, 'Functional Cookies', 'Analytics and Performance Cookies' and description value must be short one line for the web cookie named {name}\"}],\n",
    "        temperature=0 )\n",
    "    text = response.choices[0].message.content.strip()  # remove any extra spaces/newlines\n",
    "    print(\"GPT:\",text)\n",
    "    result = json.loads(text)  # parse JSON\n",
    "    cookies_df.at[i, 'Category'] = result.get('Category', '').strip()\n",
    "    cookies_df.at[i, 'Description'] = result.get('Description', '').strip()\n",
    "    sucess = True #done!\n",
    "    print(f\"Got the category done!\")\n",
    "\n",
    "import openpyxl\n",
    "# Find lowest expiration timestamp\n",
    "\n",
    "# Extract the expiration dates after 2000 year\n",
    "cookies_df['Expiration'] = pd.to_datetime(cookies_df['Expiration'],errors = 'coerce')\n",
    "valid_dates = cookies_df[cookies_df['Expiration'].dt.year>=2000]['Expiration']\n",
    "print(f\"all dates:{valid_dates}\")\n",
    "\n",
    "# Find the lowest year to find the cookie scan date\n",
    "min_date = valid_dates.min()\n",
    "print(f\"Minimum date is:{min_date}\")\n",
    "\n",
    "# convert the lowest date into iSO standards\n",
    "if pd.notna(min_date):\n",
    "     manual_scan_date = min_date.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "     print(f\"manual_scan_date is:{manual_scan_date}\")\n",
    "else:\n",
    "     manual_scan_date = datetime.now().strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "     print(f\"min_date is NaT. Cannot format, so using current date {manual_scan_date}\")\n",
    "    \n",
    "# Format the expiration date format, only for the dates.\n",
    "cookies_df['Expiration'] = cookies_df['Expiration'].where(\n",
    "    cookies_df['Expiration'].apply(lambda x: isinstance(x,pd.Timestamp)), pd.NaT\n",
    ").apply(lambda x: x.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\") if pd.notna(x) else 'Infinity')\n",
    "\n",
    "# print(\"DataFrame shape:\",cookies_df.shape)\n",
    "# print(\"Column names:\",cookies_df.columns.tolist())\n",
    "# print(\"Last 5 rows:\\n\",cookies_df.head())\n",
    "\n",
    "#Avoid duplicating footer rows and Append Timestamp and Website info\n",
    "if not cookies_df.iloc[-3:, 0].str.contains(\"Time stamp of Manual Scan run\").any():     \n",
    "    cookies_df.loc[len(cookies_df)] = [''] * len(cookies_df.columns)     \n",
    "    cookies_df.loc[len(cookies_df)] = ['Time stamp of Manual Scan run', manual_scan_date] + [''] * (len(cookies_df.columns) - 2)     \n",
    "    domain_value = cookies_df['Domain'].iloc[0] if 'Domain' in cookies_df.columns else ''     \n",
    "    cookies_df.loc[len(cookies_df)] = ['Website', domain_value] + [''] * (len(cookies_df.columns) - 2) \n",
    "\n",
    "# Convert all to string before writing to Excel \n",
    "cookies_df = cookies_df.astype(str)\n",
    "\n",
    "# Write updated data to new Excel files\n",
    "with pd.ExcelWriter(output_file_name,engine='openpyxl',mode='a', if_sheet_exists ='replace') as writer:\n",
    "    cookies_df.to_excel(writer, sheet_name='Cookies', index=False)\n",
    "\n",
    "print(f\"Done,{output_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0c121",
   "metadata": {},
   "source": [
    "Local Sheet processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8caddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Local sheet\n",
    "try:\n",
    "    local_df = input_data.get('Local Storage')\n",
    "    \n",
    "    for col in ['Category', 'Description']:\n",
    "        if col not in local_df.columns:\n",
    "            local_df[col] = '' #Add new column if not exist\n",
    "    \n",
    "    print(local_df.head())\n",
    "except:\n",
    "    print(\"There is no Local Storage sheet exist\")\n",
    "#Ensure required columns exist\n",
    "\n",
    "# Process Local Storage sheet\n",
    "local_df = input_data.get('Local Storage')\n",
    "if local_df is not None:\n",
    "    for i, row in local_df.iterrows():\n",
    "        key = row['Key']  # key name\n",
    " \n",
    "        # Call ChatGPT to get category and description\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a cookie categorizer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Respond with only valid JSON object with keys 'Category' and 'Description' for local storage cookie name {key} choose the category from: 'Strictly Necessary Cookies', 'Advertising and Targetting Cookie's, 'Functional Cookies', 'Analytics and Performance Cookies' and description value must be short one line for the web cookie named {key}. the respond must be without code blocks, markdown, or extra quotes.\"}],\n",
    "            temperature=0 )\n",
    "        text = response.choices[0].message.content.strip()  # remove any extra spaces/newlines\n",
    "        print(\"GPT:\",text)\n",
    "        result = json.loads(text)  # parse JSON\n",
    "        local_df.at[i, 'Category'] = result.get('Category', '').strip()\n",
    "        local_df.at[i, 'Description'] = result.get('Description', '').strip()\n",
    "        sucess = True #done!\n",
    "        print(f\"Got the category done for local storage\")\n",
    "\n",
    "# Write updated data to new Excel files\n",
    "with pd.ExcelWriter(output_file_name,engine='openpyxl', mode='a', if_sheet_exists ='replace') as writer:\n",
    "    local_df.to_excel(writer, sheet_name='Local Storage', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75844e51",
   "metadata": {},
   "source": [
    "Session Storage Sheet processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633683cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Cookies sheet\n",
    "try:\n",
    "    session_df = input_data.get('Session Storage')\n",
    "    \n",
    "    for col in ['Category', 'Description']:\n",
    "        if col not in session_df.columns:\n",
    "            session_df[col] = '' #Add new column if not exist\n",
    "    \n",
    "    print(session_df.head())\n",
    "except:\n",
    "    print(\"There is no Session Storage sheet exist\")\n",
    "#Ensure required columns exist\n",
    "\n",
    "# Process Session Storage sheet\n",
    "session_df = input_data.get('Session Storage')\n",
    "if session_df is not None:\n",
    "    for i, row in session_df.iterrows():\n",
    "        key = row['Key']  # key name\n",
    " \n",
    "        # Call ChatGPT to get category and description\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a cookie categorizer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Respond with only valid JSON object with keys 'Category' and 'Description' for Session storage cookie name {key} choose the category from: 'Strictly Necessary Cookies', 'Advertising and Targetting Cookie's, 'Functional Cookies', 'Analytics and Performance Cookies' and description value must be short one line for the web cookie named {key}. the respond must be without code blocks, markdown, or extra quotes.\"}],\n",
    "            temperature=0 )\n",
    "        text = response.choices[0].message.content.strip()  # remove any extra spaces/newlines\n",
    "        print(\"GPT:\",text)\n",
    "        result = json.loads(text)  # parse JSON\n",
    "        session_df.at[i, 'Category'] = result.get('Category', '').strip()\n",
    "        session_df.at[i, 'Description'] = result.get('Description', '').strip()\n",
    "        sucess = True #done!\n",
    "        print(f\"Got the category done for Session storage\")\n",
    "\n",
    "# Write updated data to new Excel files\n",
    "with pd.ExcelWriter(output_file_name,engine='openpyxl', mode='a', if_sheet_exists ='replace') as writer:\n",
    "    session_df.to_excel(writer, sheet_name='Session Storage', index=False)\n",
    "\n",
    "print(\"Done!\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
